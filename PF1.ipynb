{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origen = \"lung_scc\"\n",
    "destino = \"pulmon_carcinoma\"\n",
    "\n",
    "# Listar archivos en la carpeta de origen\n",
    "archivos = os.listdir(origen)\n",
    "\n",
    "# Iterar sobre los archivos en la carpeta de origen\n",
    "for archivo in archivos:\n",
    "    ruta_origen = os.path.join(origen, archivo)\n",
    "    ruta_destino = os.path.join(destino, archivo)\n",
    "    \n",
    "    # Verificar si el archivo es una imagen (puedes agregar más extensiones si es necesario)\n",
    "    if archivo.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n",
    "        # Verificar si es un archivo (evitar carpetas u otros elementos)\n",
    "        if os.path.isfile(ruta_origen):\n",
    "            # Leer la imagen con OpenCV\n",
    "            imagen = cv.imread(ruta_origen)\n",
    "            if imagen is not None:\n",
    "                # Convertir la imagen a escala de grises\n",
    "                nueva_imagen = cv.cvtColor(imagen, cv.COLOR_BGR2GRAY)\n",
    "                # Guardar la copia con el mismo nombre en la carpeta destino\n",
    "                cv.imwrite(ruta_destino, nueva_imagen)\n",
    "                print(f'Imagen copiada y procesada: {archivo}')\n",
    "            else:\n",
    "                print(f'Error al leer: {archivo}')\n",
    "        else:\n",
    "            print(f'Omitido (no es un archivo): {archivo}')\n",
    "    else:\n",
    "        print(f'No es una imagen: {archivo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15000 files belonging to 3 classes.\n",
      "Using 12000 files for training.\n",
      "Found 15000 files belonging to 3 classes.\n",
      "Using 3000 files for validation.\n",
      "Clases asignadas: ['pulmon_adenocarcinoma', 'pulmon_benigno', 'pulmon_carcinoma']\n",
      "Entrenamiento: 375 batches\n",
      "Validación: 94 batches\n"
     ]
    }
   ],
   "source": [
    "# Parámetros\n",
    "dataset_dir = \"C:\\\\Users\\\\Dragut\\\\Desktop\\\\bobio\\\\Samsung\\\\PF\"\n",
    "batch_size = 32\n",
    "img_size = (224, 224)  # Ajusta el tamaño deseado\n",
    "validation_split = 0.2  # 20% de los datos para validación\n",
    "seed = 123  # Semilla para reproducibilidad\n",
    "\n",
    "# Carga del dataset para entrenamiento\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",        # Usamos la parte de entrenamiento\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode=\"categorical\",  # O 'int' según tus necesidades\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Carga del dataset para validación\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",      # Usamos la parte de validación\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Verificar etiquetas asignadas\n",
    "class_names = train_ds.class_names  # Debería mostrar ['cats', 'dogs']\n",
    "print(\"Clases asignadas:\", class_names)\n",
    "\n",
    "# Verificar tamaños de los datasets\n",
    "train_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "val_size = tf.data.experimental.cardinality(val_ds).numpy()\n",
    "\n",
    "print(f\"Entrenamiento: {train_size} batches\")\n",
    "print(f\"Validación: {val_size} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'], loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 [==============================] - 67s 162ms/step - loss: 0.2004 - accuracy: 0.9194 - val_loss: 6.3145 - val_accuracy: 0.3577\n",
      "Epoch 2/50\n",
      "375/375 [==============================] - 59s 156ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 4.6321 - val_accuracy: 0.5457\n",
      "Epoch 3/50\n",
      "375/375 [==============================] - 59s 156ms/step - loss: 0.0214 - accuracy: 0.9921 - val_loss: 5.9198 - val_accuracy: 0.5513\n",
      "Epoch 4/50\n",
      "375/375 [==============================] - 59s 156ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.1099 - val_accuracy: 0.9733\n",
      "Epoch 5/50\n",
      "375/375 [==============================] - 58s 155ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.1259 - val_accuracy: 0.9737\n",
      "Epoch 6/50\n",
      "375/375 [==============================] - 58s 154ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 0.4679 - val_accuracy: 0.9260\n",
      "Epoch 7/50\n",
      "375/375 [==============================] - 58s 153ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.5227 - val_accuracy: 0.9410\n",
      "Epoch 8/50\n",
      "375/375 [==============================] - 58s 154ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0694 - val_accuracy: 0.9873\n",
      "Epoch 9/50\n",
      "375/375 [==============================] - 58s 154ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.0398 - val_accuracy: 0.9920\n",
      "Epoch 10/50\n",
      "375/375 [==============================] - 58s 154ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0435 - val_accuracy: 0.9897\n",
      "Epoch 11/50\n",
      "375/375 [==============================] - 58s 155ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.2396 - val_accuracy: 0.9750\n",
      "Epoch 12/50\n",
      "375/375 [==============================] - 58s 155ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0615 - val_accuracy: 0.9887\n",
      "Epoch 13/50\n",
      "375/375 [==============================] - 59s 156ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0455 - val_accuracy: 0.9917\n",
      "Epoch 14/50\n",
      "375/375 [==============================] - 59s 156ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0191 - val_accuracy: 0.9977\n",
      "Epoch 15/50\n",
      "375/375 [==============================] - 59s 156ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0235 - val_accuracy: 0.9947\n",
      "Epoch 16/50\n",
      "375/375 [==============================] - 58s 153ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
      "Epoch 17/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0134 - accuracy: 0.9963 - val_loss: 0.1523 - val_accuracy: 0.9863\n",
      "Epoch 18/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.0161 - val_accuracy: 0.9967\n",
      "Epoch 19/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
      "Epoch 20/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2804 - val_accuracy: 0.9557\n",
      "Epoch 21/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0094 - accuracy: 0.9975 - val_loss: 0.0163 - val_accuracy: 0.9977\n",
      "Epoch 22/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0131 - accuracy: 0.9975 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "Epoch 23/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.2382 - val_accuracy: 0.9750\n",
      "Epoch 24/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0200 - val_accuracy: 0.9967\n",
      "Epoch 25/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 6.1435e-04 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9993\n",
      "Epoch 26/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 1.8350e-04 - accuracy: 1.0000 - val_loss: 1.7611e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.0759 - val_accuracy: 0.9930\n",
      "Epoch 28/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.2246 - val_accuracy: 0.9767\n",
      "Epoch 29/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.5994 - val_accuracy: 0.9543\n",
      "Epoch 30/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0544 - val_accuracy: 0.9897\n",
      "Epoch 31/50\n",
      "375/375 [==============================] - 56s 150ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.1723 - val_accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       # Monitorea la pérdida de validación\n",
    "    patience=5,               # Si no mejora en 5 épocas consecutivas, se detiene\n",
    "    restore_best_weights=True # Restaura los mejores pesos durante el entrenamiento\n",
    ")\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 5s 49ms/step - loss: 1.7611e-04 - accuracy: 1.0000\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Evaluamos el modelo\n",
    "loss, accuracy = model.evaluate(val_ds)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# Crear las listas de etiquetas verdaderas y predicciones\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    y_true_list.append(labels.numpy())  # Convertimos las etiquetas a numpy\n",
    "    y_pred_probs = model.predict(images)  # Predecimos las probabilidades\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)  # Convertimos las probabilidades a 0 o 1\n",
    "    y_pred_list.append(y_pred_labels)  # Guardamos las predy_test_clases = np.argmax(y_true, axis=1)icciones\n",
    "    \n",
    "y_test_clases = np.argmax(y_true, axis=1)\n",
    "\n",
    "# Unir las listas de etiquetas verdaderas y predicciones\n",
    "y_true = np.concatenate(y_true_list)\n",
    "y_test_clases = np.argmax(y_true, axis=1)\n",
    "y_pred = np.concatenate(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Crear la matriz de confusión\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Visualizarla con seaborn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dragut\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Dragut\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\Users\\Dragut\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "# Crear la matriz de confusión\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Visualizarla con seaborn\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicho\")\n",
    "plt.ylabel(\"Verdadero\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
